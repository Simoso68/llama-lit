# Llama-Lit

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/Simoso68/llama-lit/llama-lit/)

Llama-Lit is a streamlit page providing a front-end to interact with the Llama model. \
This is still in development and needs some adjustment to offer a good user experience. \
\
The backend was made using the [ollama](https://github.com/ollama/ollama-python) library. \
Please keep in mind, that this module uses the first module listed when executing the function ```ollama.list()``` from the library itself. \
Meaning, it is not guaranteed to use a Llama model. \
\
The frontend was made with [streamlit](https://streamlit.io). \
If one wants to host this application themselves, they would need to install all [requirements](https://github.com/Simoso68/llama-lit/blob/main/requirements.txt) and run the script via ```streamlit run app.py```.

## Using it

ðŸš§ This part of the README is not completed yet ðŸš§